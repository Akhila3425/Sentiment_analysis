# Sentiment_analysis

*CAMPANY*: CODTECH IT SOLUTIONS

*NAME*: POLU AKHILA

*INTERN ID*: CT04DZ2019

*DOMAIN*: DATA ANALYTICS

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTOSH


The given Python code is a complete pipeline for performing sentiment analysis on tweets, starting from raw data preprocessing to model training and evaluation. First, the script begins by importing essential libraries such as pandas for data handling, seaborn and matplotlib for visualization, re for regular expressions in text cleaning, and several modules from scikit-learn that support data splitting, feature extraction, machine learning modeling, and evaluation. The dataset, which contains tweets and their associated sentiment labels, is read into a pandas DataFrame from a CSV file. Since text and sentiment are critical for analysis, the code checks for missing values and removes any rows where these columns are null, ensuring that the dataset is clean and reliable for training. To understand the dataset better, a class distribution plot is generated using seaborn, showing how many samples fall under each sentiment category—positive, negative, or neutral. This is important because imbalanced classes can bias the model toward predicting the majority sentiment. Next, the tweets undergo preprocessing to remove noise and make them uniform. The clean_text function converts all text to lowercase, removes URLs, mentions, hashtags, punctuation, and numerical values using regular expressions. This step is crucial because raw tweets often contain irrelevant characters, links, and symbols that can confuse the model. For example, a tweet like “Great service! Visit https://example.com
 #happy” would be simplified to “great service visit happy,” which preserves the meaningful words while discarding unnecessary ones. After cleaning, the script encodes categorical sentiment labels into numerical values using LabelEncoder, since machine learning models cannot work with text labels directly. For instance, “neutral” may be mapped to 0, “negative” to 1, and “positive” to 2. Once the data is prepared, it is split into training and testing subsets using train_test_split, with 80% of the data used to train the model and 20% reserved for testing. The split is stratified to maintain equal distribution of sentiment classes across training and testing sets. To efficiently process the text data and train the classifier, a scikit-learn pipeline is created. This pipeline first applies TF-IDF (Term Frequency–Inverse Document Frequency) vectorization, which transforms tweets into numerical vectors by assigning higher weights to words that are frequent in a document but not common across all documents, thereby emphasizing informative words. The second step in the pipeline is logistic regression, a robust classification algorithm that learns patterns in the transformed vectors and predicts the sentiment of new, unseen tweets. The pipeline is trained on the training set, and then predictions are generated for the test set. To evaluate model performance, the code calculates accuracy, which measures the percentage of correct predictions, and generates a classification report showing precision, recall, and F1-scores for each sentiment class. This gives deeper insights into how well the model handles each category individually, especially in the case of imbalanced data. Finally, a confusion matrix is computed and visualized using seaborn’s heatmap. The confusion matrix provides a clear view of true positives, true negatives, and misclassifications across sentiment categories, helping diagnose where the model performs well and where it struggles. For instance, it may correctly classify most positive tweets but confuse neutral ones as negative. Altogether, this code provides a structured workflow: loading and cleaning the data, preparing features and labels, splitting data, vectorizing text, training a logistic regression classifier, and evaluating results with both metrics and visualizations. By chaining preprocessing and classification in a pipeline, the approach ensures efficiency and clarity. The final outcome is a sentiment analysis model capable of automatically categorizing tweets as positive, negative, or neutral with good accuracy, making it a useful tool for understanding public opinion or monitoring social media feedback.

OUTPUT
<img width="1392" height="783" alt="Image" src="https://github.com/user-attachments/assets/cf838183-d7cf-4c7a-b868-e7fbcf494e05" />

<img width="1536" height="813" alt="Image" src="https://github.com/user-attachments/assets/a8d4bb49-e006-46d0-99dc-da16fb800ea2" />

